{"nbformat":4,"nbformat_minor":0,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9-final"},"orig_nbformat":2,"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"colab":{"name":"pickle_export.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"id":"Mixt5ydu5T1U"},"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn import model_selection\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.svm import SVC\n","\n","from sklearn.model_selection import train_test_split"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pD_N-FJY5T1d"},"source":["imdb = pd.read_csv('/home/kafka/kafka/imdb.csv', encoding='ISO-8859-1')\n","#imdb['label'].value_counts()\n","#imdb.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IQYrGvuR5T1e"},"source":["imdb_ok = imdb[['review', 'label']]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0rSZKkTI5T1f"},"source":["imdb = imdb_ok[imdb_ok.label != \"unsup\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s4sWlNNV5T1f"},"source":["def label_sentiment (row):\n","\n","  if row['label'] == \"neg\" :\n","    return 0\n","  if row['label'] == \"pos\" :\n","    return 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wPT8sGuz5T1f","outputId":"4083b1b6-30d5-4aba-b792-26873625b7f6"},"source":["imdb_def = imdb.apply (lambda row: label_sentiment(row), axis=1)\n","imdb_def"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0        0\n","1        0\n","2        0\n","3        0\n","4        0\n","        ..\n","49995    1\n","49996    1\n","49997    1\n","49998    1\n","49999    1\n","Length: 50000, dtype: int64"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"anbiHbr25T1h","outputId":"ccca5098-cfac-4d7f-949d-b2171bdb7758"},"source":["imdb['target'] = imdb_def\n","imdb.tail()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                  review label  target\n","49995  Seeing as the vote average was pretty low, and...   pos       1\n","49996  The plot had some wretched, unbelievable twist...   pos       1\n","49997  I am amazed at how this movie(and most others ...   pos       1\n","49998  A Christmas Together actually came before my t...   pos       1\n","49999  Working-class romantic drama from director Mar...   pos       1"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>review</th>\n","      <th>label</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>49995</th>\n","      <td>Seeing as the vote average was pretty low, and...</td>\n","      <td>pos</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>49996</th>\n","      <td>The plot had some wretched, unbelievable twist...</td>\n","      <td>pos</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>49997</th>\n","      <td>I am amazed at how this movie(and most others ...</td>\n","      <td>pos</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>49998</th>\n","      <td>A Christmas Together actually came before my t...</td>\n","      <td>pos</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>49999</th>\n","      <td>Working-class romantic drama from director Mar...</td>\n","      <td>pos</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"LTIvOvDA5T1h"},"source":["seed = 123"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qoti5ihb5T1i"},"source":["# Measuring run time\n","from time import time\n","\n","# Data manipulation/analysis\n","import numpy as np\n","\n","# Text preprocessing/analysis\n","import re, random\n","from nltk import word_tokenize, sent_tokenize, pos_tag\n","from nltk.util import ngrams\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer\n","from nltk.tokenize import RegexpTokenizer\n","from sklearn.feature_extraction.text import TfidfVectorizer"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BEdTFtYx5T1j"},"source":["\n","def preprocess_text(text):\n","    # 1. Tokenise to alphabetic tokens\n","    tokeniser = RegexpTokenizer(r'[A-Za-z]+')\n","    tokens = tokeniser.tokenize(text)\n","\n","    # 2. Lowercase and lemmatise \n","    lemmatiser = WordNetLemmatizer()\n","    tokens = [lemmatiser.lemmatize(t.lower(), pos='v') for t in tokens]\n","    return tokens"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X1Se7VN75T1j"},"source":["vectoriser = TfidfVectorizer(analyzer=preprocess_text, min_df=30, max_df=.7)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"13g1_FIt5T1k"},"source":["from sklearn.pipeline import Pipeline\n","from sklearn.linear_model import LogisticRegression, SGDClassifier\n","from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV, RandomizedSearchCV\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MfVii11s5T1k"},"source":["X_train, X_test, y_train, y_test = train_test_split(imdb['review'], imdb['target'], test_size=5000, random_state=seed)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TxUvSjdr5T1k","outputId":"22ad3da3-803f-46a4-c91d-3302126a46eb"},"source":["pipe = Pipeline([('vectoriser', \n","                  TfidfVectorizer(token_pattern=r'[a-z]+', \n","                                  min_df=30, \n","                                  max_df=.6, \n","                                  ngram_range=(1,2))),\n","                 ('model', \n","                  SGDClassifier(random_state=seed, loss='hinge'))])\n","\n","pipe.fit(X_train, y_train)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Pipeline(steps=[('vectoriser',\n","                 TfidfVectorizer(max_df=0.6, min_df=30, ngram_range=(1, 2),\n","                                 token_pattern='[a-z]+')),\n","                ('model', SGDClassifier(random_state=123))])"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"MX6GQE2R5T1k","outputId":"ea846b0b-2ecd-466f-e223-082e584b0101"},"source":["############# THE COEFICIENTS OF OUR PIPELINE \n","\n","coefs = pd.DataFrame(pipe['model'].coef_, \n","                     columns=pipe['vectoriser'].get_feature_names())\n","\n","coefs = coefs.T.rename(columns={0:'coef'}).sort_values('coef')\n","\n","\n","#### CHECK REUSLTS\n","print(coefs.head(10))\n","print('\\n')\n","print(coefs.tail(10))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["               coef\n","bad       -4.959635\n","worst     -4.603756\n","awful     -4.118285\n","boring    -3.778384\n","the worst -3.594560\n","poor      -3.436840\n","terrible  -3.126976\n","waste     -2.959757\n","nothing   -2.949903\n","worse     -2.608583\n","\n","\n","               coef\n","well       2.079229\n","today      2.342685\n","brilliant  2.350588\n","the best   2.373143\n","amazing    2.404742\n","fun        2.416445\n","wonderful  2.466989\n","perfect    2.682182\n","excellent  3.656383\n","great      4.111817\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xx9_uE1I5T1l"},"source":["from sklearn.metrics import classification_report, confusion_matrix"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QpDqK6fy5T1l","outputId":"de8055d6-9241-4303-ebf3-da5a23cf7533"},"source":["train_pred = pipe.predict(X_train)\n","target_names=['negative', 'positive']\n","print(classification_report(train_pred, \n","                            y_train, \n","                            target_names=target_names))\n","                            "],"execution_count":null,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","    negative       0.93      0.94      0.94     22150\n","    positive       0.95      0.93      0.94     22850\n","\n","    accuracy                           0.94     45000\n","   macro avg       0.94      0.94      0.94     45000\n","weighted avg       0.94      0.94      0.94     45000\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rHxP4jb15T1m"},"source":["import pickle"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4s5ke4uY5T1m"},"source":["# Dump the trained decision tree classifier with Pickle\n","pipe_filename = './home/kafka/kafka/model.pkl'\n","# Open the file to save as pkl file\n","decision_tree_model_pkl = open(pipe_filename, 'wb')\n","pickle.dump(pipe, decision_tree_model_pkl)\n","# Close the pickle instances\n","decision_tree_model_pkl.close()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OobAShy15T1m"},"source":[""],"execution_count":null,"outputs":[]}]}